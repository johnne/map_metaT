# Main entrypoint of the workflow. 
# Please follow the best practices: 
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there. 

configfile: "config/config.yml"
include: "rules/common.smk"

localrules:
    clean_featurecount,
    multiqc,
    count_features,
    css_normalize_features,
    rpkm,
    zip,
    edger_normalize_features

rule all:
    input:
        expand("results/{assembly}/count/{sample}.{suff}",
            assembly = assemblies.keys(), sample=samples.keys(), suff=["fc.tsv", "fc.tsv.summary"]),
        expand("results/{assembly}/counts.tsv",
            assembly = assemblies.keys()),
        expand("results/{assembly}/{db}.parsed.{norm}.tsv",
            assembly=assemblies.keys(), db=config["annotation_dbs"], norm = config["norm_methods"]),
        expand("tables/{db}.parsed.{norm}.tsv",
            db=config["annotation_dbs"], norm = config["norm_methods"])

rule zip:
    input:
        "{f}.fastq"
    output:
        "{f}.fastq.gz"
    shell:
        """
        gzip -c {input} > {output}
        """

rule bowtie_build:
    input:
        expand("{assembly_dir}/{{assembly}}/final_contigs.fa",
            assembly_dir=config["assembly_dir"])
    output:
        expand("{assembly_dir}/{{assembly}}/final_contigs.fa.{index}.bt2l",
            assembly_dir=config["assembly_dir"], index=list(range(1,5))+["rev.1", "rev.2"])
    params: prefix=f"{config['assembly_dir']}/"+"{assembly}/final_contigs.fa"
    threads: config["bowtie2"]["threads"]
    resources:
        runtime=lambda wildcards, attempt: attempt**2*60*4
    conda:
        "envs/bowtie2.yml"
    shell:
        """
        bowtie2-build \
            --large-index \
            --threads {threads} \
            {params.prefix} \
            {params.prefix} > /dev/null 2>&1
        """

rule align:
    input:
        fq1 = lambda wildcards: samples[wildcards.sample]["fq1"],
        fq2 = lambda wildcards: samples[wildcards.sample]["fq2"],
        asm = expand("{assembly_dir}/{{assembly}}/final_contigs.fa.{n}.bt2l",
            n = ["1","2","3","rev.1","rev.2"], assembly_dir=config["assembly_dir"])
    output:
        bam = temp("results/{assembly}/align/{sample}.bam"),
        bai = temp("results/{assembly}/align/{sample}.bam.bai"),
    log:
        "logs/{assembly}/{sample}.bt2.log"
    params:
        index = lambda wildcards, input: f"{os.path.dirname(input.asm[0])}/final_contigs.fa",
        temp_bam = "$TMPDIR/{assembly}.{sample}.bam",
        outdir = lambda wildcards, output: os.path.dirname(output.bam),
        setting = config["bowtie2"]["settings"]
    conda: "envs/bowtie2.yml"
    resources:
        runtime = lambda wildcards, attempt: attempt ** 2 * 60 * 10
    threads: config["bowtie2"]["threads"]
    shell:
        """
        bowtie2 {params.setting} -1 {input.fq1} -2 {input.fq2} -p {threads} -x {params.index} 2> {log} | \
            samtools view -bh - | samtools sort - -o {params.temp_bam}
        samtools index {params.temp_bam}
        mv {params.temp_bam} {output.bam}
        mv {params.temp_bam}.bai {output.bai}
        """


rule featurecount:
    input:
        gff = expand("{annotation_dir}/{{assembly}}/final_contigs.gff",
            annotation_dir = config["annotation_dir"]),
        bam = rules.align.output.bam
    output:
        tsv = "results/{assembly}/count/{sample}.fc.tsv",
        summary = "results/{assembly}/count/{sample}.fc.tsv.summary"
    log:
        "logs/{assembly}/{sample}.fc.log"
    threads: 4
    params:
        tmpdir="$TMPDIR",
        setting=config["featurecounts"]["settings"]
    resources:
        runtime=lambda wildcards, attempt: attempt**2*30
    conda:
        "envs/featurecounts.yml"
    shell:
        """
        mkdir -p {params.tmpdir}
        featureCounts {params.setting} -a {input.gff} -o {output.tsv} \
            -T {threads} --tmpDir {params.tmpdir} {input.bam} > {log} 2>&1
        """

rule clean_featurecount:
    input:
        tsv = expand("results/{{assembly}}/count/{sample}.fc.tsv",
            sample = samples.keys())
    output:
        tsv = "results/{assembly}/counts.tsv"
    priority: 50
    script: "scripts/common.py"

rule extract_counts:
    input:
        expand("results/{assembly}/{{db}}.parsed.counts.tsv",
            assembly = assemblies.keys())
    output:
        "tables/{db}.parsed.counts.tsv"
    params:
        sample_list = config["sample_list"]
    script:
        "scripts/common.py"

rule multiqc:
    input:
        bt = expand("logs/{{assembly}}/{sample}.bt2.log",
            sample = samples.keys()),
        fc = expand("results/{{assembly}}/count/{sample}.fc.tsv.summary",
            sample = samples.keys())
    output:
        "results/{assembly}/report.html"
    log:
        "logs/{assembly}/multiqc.log"
    params:
        outdir = lambda wildcards, output: os.path.dirname(output[0])
    conda: "envs/multiqc.yml"
    shadow: "minimal"
    shell:
        """
        echo {input} | tr ' ' '\n' > filelist
        multiqc --cl-config 'extra_fn_clean_exts: [".bt2.log"]' -n report.html -o {params.outdir} -f -l filelist > {log} 2>&1
        """

rule rpkm:
    """
    Calculate RPKM for genes in an assembly
    """
    input:
        "results/{assembly}/counts.tsv"
    output:
        "results/{assembly}/rpkm.tsv"
    log:
        "logs/{assembly}/rpkm.log"
    params:
        method = "RPKM"
    conda:
        "envs/edger.yml"
    script:
        "scripts/edger.R"


rule count_features:
    """
    Sums read counts for gene annotation features such as pfam, KOs etc.
    """
    input:
        abund = "results/{assembly}/counts.tsv",
        annot = expand("{annotation_dir}/{{assembly}}/{{db}}.parsed.tsv",
            annotation_dir = config["annotation_dir"])
    output:
        "results/{assembly}/{db}.parsed.counts.tsv"
    script:
        "scripts/common.py"

rule edger_normalize_features:
    """
    Normalizes counts of features using TMM and REL
    """
    input:
        counts = "{dir}/{db}.parsed.counts.tsv"
    output:
        "{dir}/{db}.parsed.{norm_method}.tsv"
    log:
        "{dir}/logs/{db}.{norm_method}.log"
    params:
        method = "{norm_method}"
    conda:
        "envs/edger.yml"
    script:
        "scripts/edger.R"

rule css_normalize_features:
    """
    Normalizes counts of features using CSS from metagenomeSeq
    """
    input:
        counts = "{dir}/{db}.parsed.counts.tsv"
    output:
        "{dir}/{db}.parsed.CSS.tsv"
    log:
        "{dir}/logs/{db}.CSS.log"
    conda:
        "envs/metagenomeseq.yml"
    script:
        "scripts/metagenomeseq.R"
